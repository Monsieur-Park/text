---
layout: page
title: xwMOOC 자연어 처리 - 텍스트
subtitle: 텍스트 데이터 수집 및 단어문서행렬(TDM) -- 트위터
output:
  html_document: 
    toc: yes
  pdf_document:
    latex_engine: xelatex
mainfont: NanumGothic
---
 
> ## 학습목표 {.objectives}
>
> * 텍스트 문자 데이터 분석을 위해 텍스트 데이터를 가져온다.
> * 트위터 서비스를 통해 텍스트 문자 데이터를 R로 불러온다. 
> * 트위터에서 트윗을 불러와서 단어문서행렬로 변환한다.
> * 전처리 과정을 거쳐 단어 빈도수를 단어문서행렬을 통해 산출한다.
> * 막대그래프로 빈도수 높은 단어를 시각화한다.


``` {r, include=FALSE}
source("tools/chunk-options.R")
```

## 1. 트위터 서비스 {#nlp-twitter}

"트윗(tweet)"이란 말은 작은 새가 지저귀는 소리를 나타내는 영어 낱말로, 
[트위터(영어: Twitter)](https://www.twitter.com/)는 **소셜 네트워크 서비스(SNS)**이자 **마이크로블로그** 서비스로 볼 수 있다.

단문 메시지 서비스(SMS), 인스턴트 메신저, 전자 우편(e-mail) 등을 통해 "트윗(tweet)"를 전송할 수 있고, 글 한 편에 해당하는 단위는 트윗으로 140자가 한도가 된다. 
한글이든 영문이든, 공백과 기호를 포함해 한 번에 140 까지 글자를 올릴 수 있다.

### 1.1. 트위터 계정과 핸드폰 번호 등록 {#nlp-twitter-setup}

텍스트 문자 데이터를 R로 받아오기 위해서는 먼저 트위터 계정을 생성하고 핸드폰 번호를 등록하고 인증과정을 거쳐야 된다.

`Settings` &rarr; `Mobile` 로 들어가서 핸드폰 번호 인증을 받는다.

인증된 핸드폰 번호가 있어야 [트위터 개발자 페이지](https://dev.twitter.com/)에서 앱개발에 대한 키값을 받을 수 있다.

### 1.2. 트위터 개발자 페이지 {#nlp-twitter-developer}

트위터 계정을 생성하고, 핸드폰 인증을 마친 뒤에 [트위터 개발자 페이지](https://dev.twitter.com/)에서 **TOOLS** 메뉴를 찾아 
[Manage Your Apps](https://apps.twitter.com/)로 들어간다. 이유는 트위터 데이터를 통해 부가적인 가치를 창출하는 응용프로그램을 개발해야 되기 때문이다.

1. **Create New App** 을 클릭하여 신규 응용프로그램을 개발한다.
    * 굳이 응용프로그램 개발하는 경우가 아니고, 향후 응용프로그램을 개발하는 것을 대비해서 기본적인 정보를 적어 놓는다. 
    * 모든 정보를 다 넣을 필요는 없다. `Name`, `Description`, `Website`는 필수 값으로 기재를 하고, `Website`는 정확한 주소 정보가 아니더라도 상관없다.
1. **Create your Twitter application** 을 클릭하면 트위터 응용프로그램이 생성된다.
    * 핸드폰 번호를 등록하지 않는 경우 다음으로 넘어가지 않아서 상기 "트위터 계정과 핸드폰 번호 등록"을 통해 필히 핸드폰을 등록한다.

### 1.3. 키값과 접속 토큰 {#nlp-twitter-developer-token}

응용프로그램이 생성되었으면 다음으로 남은 단계는 **고객 키(Consumer Key)** 와 **비밀번호(Consumer Secret)** 와 더불어 **접속 토큰(Access Token)** 과
**접속 토큰 비밀번호(Access Secret)** 를 확인한다. 만약 의심스러운 경우 지체없이 `Regenerate` 버튼을 눌러 재생성한다.

* consumer_key   
* consumer_secret
* access_token   
* access_secret  

## 2. `twitteR` 트위터 데이터 긁어오기 {#nlp-twitter-api}

오랜기간동안 트위터가 서비스 되었고, R을 활용한 데이터 분석이 인기를 끌어 쉽게 텍스트 문자정보를 긁어와서 분석을 수월하게 진행할 수 있다.
`twitteR`과 `ROAuth` 팩키지를 설치하고 트위터 개발자 페이지, 앱 개발 페이지에서 수집한 고객키값과 접속토큰값을 `twitterOAuth.R` 파일에
저장한다. 

그리고, `source` 명령어로 파일을 불러와서 메모리에 올리고 `setup_twitter_oauth` 명령어를 통해 트위터 인증을 한다.

`searchTwitter` 명령어로 검색어를 넣고 **@HQ_sohn** 넣고, 한글로 언어를 설정하고, `lang='ko'`, 긁어올 트윗 갯수를 `n=100`으로 지정한다.
긁어온 데이터는 리스트 정보라 이를 `twListToDF` 명령어를 통해 데이터프레임으로 변환한다.

`head(hq_tweets_df$text)` 명령어를 통해 트위터를 잘 긁어왔는지 확인한다.


``` {r ml-text-twitter-import, warning=FALSE, eval=FALSE}
##======================================================================================================
## 01. 트위터 데이터 가져오기
##======================================================================================================

rm(list=ls())

library(twitteR)
library(ROAuth)

source("twitterOAuth.R")

# twitterOAuth.R 파일에 담겨있는 정보
#
# consumer_key    <- "..............."
# consumer_secret <- "..............."
# access_token    <- "..............."
# access_secret   <- "..............."

setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)

[1] "Using direct authentication"

hq_tweets <- searchTwitter("@HQ_sohn", lang='ko', n=100)
hq_tweets_df <- twListToDF(hq_tweets)
head(hq_tweets_df$text)

[1] "RT @justice7200: 손학규 @HQ_Sohn  고문님 역할 기대돼요. 정권교체 주역도, 킹메이커도 가능한 분. 다만 국민의 당은 잊으세요. https://t.co/ff8mXcopfg"                                                                                
[2] "RT @justice7200: 손학규@HQ_Sohn 고문님. 정치활동 멋 있게 잘 하셔서 경선하여 승리하시면 정권교체도 가능합니다. 아름다운 경선이 조건. 보이콧 마시고 문재인 전 대표님과 손잡고 아름다운 경선하세요. 문대표님은 그럴맘이 준비된 분.…"
[3] "RT @justice7200: 손학규@HQ_Sohn 고문님. 정치활동 멋 있게 잘 하셔서 경선하여 승리하시면 정권교체도 가능합니다. 아름다운 경선이 조건. 보이콧 마시고 문재인 전 대표님과 손잡고 아름다운 경선하세요. 문대표님은 그럴맘이 준비된 분.…"
[4] "RT @justice7200: 손학규 @HQ_Sohn  고문님 역할 기대돼요. 정권교체 주역도, 킹메이커도 가능한 분. 다만 국민의 당은 잊으세요. https://t.co/ff8mXcopfg"                                                                                
[5] "RT @justice7200: 손학규@HQ_Sohn 고문님. 정치활동 멋 있게 잘 하셔서 경선하여 승리하시면 정권교체도 가능합니다. 아름다운 경선이 조건. 보이콧 마시고 문재인 전 대표님과 손잡고 아름다운 경선하세요. 문대표님은 그럴맘이 준비된 분.…"
[6] "안철수, 1박2일 호남행…박지원은 손학규와 회동&lt;=손학규(@HQ_Sohn)님,모바일 부정의혹으로 대선후보 앗아간 문재인에게 미련갖지 마시길,공정경선하고,여의치 않으면 길을 돌아 가는 것도 생각해 보셨으면^^ https://t.co/CuIJ0NDnDt"    
```

## 3. 단어문서행렬 {#nlp-twitter-tdm}

### 3.1. 트위터 인증 {#nlp-twitter-tdm-auth}

`text_processing_fun.R` 함수내에 `twitter_auth()` 인증함수로 저장하여 인증과정을 캡슐화하여 숨겨놓는다.

``` {r twitter-auth, eval=FALSE}
##======================================================================================================
## 01. 트위터 인증
##======================================================================================================
rm(list=ls())

source("text_processing_fun.R")
# twitter_auth(): 트위터 계정 인증
# twitter_clean_text(): 트위터 텍스트 전처리 
# twitter_word_cloud(): 단어구름 시각

twitter_auth()

[1] "Using direct authentication"
```

### 3.2. 트위터 데이터 불러오기 {#nlp-twitter-tdm-import}

`twitter_auth()`를 통해 인증을 거친 뒤에 `searchTwitter` 함수를 통해 `#rstats` 해쉬태그를 갖는 트윗을 
불러온다. 원활한 데이터 작업을 위해 `twListToDF` 함수로 트윗 리스트를 데이터프레임으로 변환한다.

```{r twitter-search, eval=FALSE}
##======================================================================================================
## 02. 트위터 데이터 가져오기
##======================================================================================================

tw <- searchTwitter('#rstats', n = 100, lang="en", since = '2016-04-01')
tw_rd_df <- twListToDF(tw)
```

### 3.3. 트위터 데이터 전처리 {#nlp-twitter-tdm-preprocessing}

`twitter_clean_text` 함수를 통해 텍스트 트윗 메시지를 전처리한다. 전처리 과정에는 
소문자 변환, 구두점 제거, 불용어 처리 등등이 포함된다.

```{r twitter-prerpocessing, eval=FALSE}
##======================================================================================================
## 03. 트위터 데이터 전처리
##======================================================================================================
tw_df <- twitter_clean_text(tw_rd_df$text)
```

### 3.4. 단어문서행렬 {#nlp-twitter-tdm-matrix}

단어분석행렬을 통한 방법이 일반적으로 많이 사용된다. 이를 위해 입력값이 데이터프레임인 경우 `DataframeSource`,
벡터인 경우 `VectorSource`를 사용하여 말뭉치(Corpus)로 변환하고, 이를 `TermDocumentMatrix` 함수에 넣어 
단어문서행렬을 생성한다.

물론 텍스트를 바로 넣어 `wfm` 단어빈도행렬(Word Frequency Matrix)을 생성시켜 분석을 하기도 하지만 일반적인 방식은 아니다. 

```{r twitter-tdm, eval=FALSE}
##======================================================================================================
## 04. TDM, DTM
##======================================================================================================
suppressMessages(library(tm))
suppressMessages(library(qdap))
#tw_corpus <- VCorpus(DataframeSource(tw_rd_df[,1:2]))
tw_corpus <- Corpus(VectorSource(tw_df))

# tdm
tw_tdm <- TermDocumentMatrix(tw_corpus)

# dtm
tw_dtm <- DocumentTermMatrix(tw_corpus)

# wfm
library(qdap)
suppressMessages(library(dplyr))
tw_wfm <- data.frame(wfm(tw_df))
tw_wfm$term <- rownames(tw_wfm)
tw_wfm %>% arrange(desc(all)) %>% head(10)

   all    term
1   50  rstats
2   37     for
3   36       r
4   27      in
5   25     the
6   25    with
7   20      to
8   16       a
9   15     new
10  15 package
```


### 3.5. 빈도수 분석 및 시각화 {#nlp-twitter-tdm-barplot}

단어문서행렬이 생성되면 이를 행렬로 변환하여 행방향으로 합을 구하면 단어빈도수가 계산되고,
열방향으로 합을 구하면 문서빈도수가 계산된다. 단어 빈도수를 내림차순으로 계산하고 나서,
가장 많이 사용되는 단여 10개를 골라 막대그래프로 시각화한다.

```{r twitter-freq, eval=FALSE}
# 단어주머니 빈도 분석
tw_tdm_m <- as.matrix(tw_tdm)
term_freq <- rowSums(tw_tdm_m)
term_freq <- sort(term_freq, decreasing = TRUE)

barplot(term_freq[1:10], col = "tan", las=2)
```          

<img src="fig/twitter-freq-1.png" alt="트위터 막대그래프" width="57%" />
